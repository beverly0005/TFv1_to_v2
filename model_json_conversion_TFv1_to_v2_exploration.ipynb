{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/MyDrive/Colab'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGs0YzGrZAmq",
        "outputId": "2eda8d9b-f4d1-4a84-e52b-768e58386811"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VySBBB1rtvj6",
        "outputId": "19686398-e1f5-47c3-d7a2-7f7797211c17"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from Keras-Preprocessing) (2.0.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Keras-Preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Test (Create Model Json File and Load)"
      ],
      "metadata": {
        "id": "bmRfkvI3IXj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, BatchNormalization, Dense, Embedding\n",
        "\n",
        "# Define model parameters\n",
        "vocab_size = 10000   # Vocabulary size\n",
        "embedding_dim = 128  # Word embedding dimension\n",
        "input_length = 100   # Max sequence length\n",
        "num_classes = 5      # Number of output classes\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),  # Embedding layer\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),  # BiLSTM layer (with sequence output)\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),  # Batch Normalization\n",
        "    Bidirectional(LSTM(32, return_sequences=False)),  # Another BiLSTM layer\n",
        "    Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_classes, activation='softmax')  # Output layer for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.build((256, None))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Load Model from JSON\n",
        "config_model = model.to_json()\n",
        "loaded_model = keras.models.model_from_json(config_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "60o5PMy2IXWG",
        "outputId": "9ae81f9c-54fe-416f-bca6-9cfd36cc6454"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │          \u001b[38;5;34m41,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m5\u001b[0m)                    │             \u001b[38;5;34m325\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,421,125\u001b[0m (5.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421,125</span> (5.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,420,741\u001b[0m (5.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,420,741</span> (5.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "pXC6JLXsIikP",
        "outputId": "34e21ca7-1e1d-407a-a7ac-ff40c7790f31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"module\": \"keras\", \"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"layers\": [{\"module\": \"keras.layers\", \"class_name\": \"InputLayer\", \"config\": {\"batch_shape\": [256, null], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"input_layer\"}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Embedding\", \"config\": {\"name\": \"embedding\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"input_dim\": 10000, \"output_dim\": 128, \"embeddings_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"RandomUniform\", \"config\": {\"seed\": null, \"minval\": -0.05, \"maxval\": 0.05}, \"registered_name\": null}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": false}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null]}}, {\"module\": \"keras.layers\", \"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"merge_mode\": \"concat\", \"layer\": {\"module\": \"keras.layers\", \"class_name\": \"LSTM\", \"config\": {\"name\": \"forward_lstm\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"return_sequences\": true, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": true, \"units\": 64, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Orthogonal\", \"config\": {\"seed\": null, \"gain\": 1.0}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null, 128]}}, \"backward_layer\": {\"module\": \"keras.layers\", \"class_name\": \"LSTM\", \"config\": {\"name\": \"backward_lstm\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"return_sequences\": true, \"return_state\": false, \"go_backwards\": true, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": true, \"units\": 64, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Orthogonal\", \"config\": {\"seed\": null, \"gain\": 1.0}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null, 128]}}}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null, 128]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"rate\": 0.5, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"BatchNormalization\", \"config\": {\"name\": \"batch_normalization\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"axis\": -1, \"momentum\": 0.99, \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"moving_mean_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"moving_variance_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null, \"synchronized\": false}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null, 128]}}, {\"module\": \"keras.layers\", \"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional_1\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"merge_mode\": \"concat\", \"layer\": {\"module\": \"keras.layers\", \"class_name\": \"LSTM\", \"config\": {\"name\": \"forward_lstm_1\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"return_sequences\": false, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": false, \"units\": 32, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Orthogonal\", \"config\": {\"seed\": null, \"gain\": 1.0}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null, 128]}}, \"backward_layer\": {\"module\": \"keras.layers\", \"class_name\": \"LSTM\", \"config\": {\"name\": \"backward_lstm_1\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"return_sequences\": false, \"return_state\": false, \"go_backwards\": true, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": false, \"units\": 32, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Orthogonal\", \"config\": {\"seed\": null, \"gain\": 1.0}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null, 128]}}}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null, 128]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"rate\": 0.3, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"BatchNormalization\", \"config\": {\"name\": \"batch_normalization_1\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"axis\": -1, \"momentum\": 0.99, \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"moving_mean_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"moving_variance_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null, \"synchronized\": false}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, 64]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"units\": 5, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, 64]}}], \"build_input_shape\": [256, null]}, \"registered_name\": null, \"build_config\": {\"input_shape\": [256, null]}, \"compile_config\": {\"optimizer\": {\"module\": \"keras.optimizers\", \"class_name\": \"Adam\", \"config\": {\"name\": \"adam\", \"learning_rate\": 0.0010000000474974513, \"weight_decay\": null, \"clipnorm\": null, \"global_clipnorm\": null, \"clipvalue\": null, \"use_ema\": false, \"ema_momentum\": 0.99, \"ema_overwrite_frequency\": null, \"loss_scale_factor\": null, \"gradient_accumulation_steps\": null, \"beta_1\": 0.9, \"beta_2\": 0.999, \"epsilon\": 1e-07, \"amsgrad\": false}, \"registered_name\": null}, \"loss\": \"categorical_crossentropy\", \"loss_weights\": null, \"metrics\": [\"accuracy\"], \"weighted_metrics\": null, \"run_eagerly\": false, \"steps_per_execution\": 1, \"jit_compile\": false}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regenerate Model Json Files (Easy Solution)"
      ],
      "metadata": {
        "id": "qkpnnXNhMqNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, BatchNormalization, Dense, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "import keras\n",
        "from keras import initializers, regularizers, constraints\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ODPcbTrfPjYv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class Attention(Layer):\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Keras Layer that implements an Attention mechanism for temporal data.\n",
        "        Supports Masking.\n",
        "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
        "        # Input shape\n",
        "            3D tensor with shape: `(samples, steps, features)`.\n",
        "        # Output shape\n",
        "            2D tensor with shape: `(samples, features)`.\n",
        "        :param kwargs:\n",
        "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "        The dimensions are inferred based on the output shape of the RNN.\n",
        "        Example:\n",
        "            model.add(LSTM(64, return_sequences=True))\n",
        "            model.add(Attention())\n",
        "        \"\"\"\n",
        "        self.supports_masking = True\n",
        "        #self.init = initializations.get('glorot_uniform')\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = 256\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
        "\n",
        "        # features_dim = self.W.shape[0]\n",
        "        # step_dim = x._keras_shape[1]\n",
        "\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "    #print weigthted_input.shape\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        #return input_shape[0], input_shape[-1]\n",
        "        return input_shape[0],  self.features_dim\n",
        "\n",
        "    # Add new\n",
        "    @classmethod\n",
        "    def from_config(cls,config):\n",
        "        return cls(**config)"
      ],
      "metadata": {
        "id": "UwleVedsPfnX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model parameters\n",
        "max_review_length = 256\n",
        "vocab_size = 99  # Vocabulary size for embedding\n",
        "embedding_dim = 300  # Embedding vector size\n",
        "input_length = max_review_length  # Maximum sequence length\n",
        "num_classes = 2199  # Number of output classes\n",
        "(embedding_matrix_shape0, embedding_matrix_shape1) = (99, 300)\n",
        "embedding_matrix = np.random.rand(embedding_matrix_shape0, embedding_matrix_shape1)\n",
        "\n",
        "inputs=Input(shape=(max_review_length,), dtype=\"int32\")\n",
        "embedding=Embedding(embedding_matrix_shape0, embedding_matrix_shape1,\n",
        "                    weights=[embedding_matrix], input_length=max_review_length)(inputs)\n",
        "lstm_out=Bidirectional(LSTM(128, return_sequences=True))(embedding)\n",
        "attention=Attention()(lstm_out)\n",
        "attention=Dense(256, activation=\"relu\")(attention)\n",
        "attention=BatchNormalization()(attention)\n",
        "output=Dense(2199, activation='softmax')(attention)\n",
        "model=Model(inputs=inputs, outputs=output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Load Model\n",
        "config_model = model.to_json()\n",
        "loaded_model = keras.models.model_from_json(config_model, custom_objects={'Attention': Attention()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "pYolz2JjIXTr",
        "outputId": "38fa823b-250a-47c1-f622-f3754207035d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │          \u001b[38;5;34m29,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m439,296\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention (\u001b[38;5;33mAttention\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2199\u001b[0m)                │         \u001b[38;5;34m565,143\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2199</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">565,143</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,101,467\u001b[0m (4.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,101,467</span> (4.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,100,955\u001b[0m (4.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,100,955</span> (4.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "gvNX73xEIXQu",
        "outputId": "e387750c-336b-4369-e589-f4b9ff3a5503"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"module\": \"keras.src.models.functional\", \"class_name\": \"Functional\", \"config\": {\"name\": \"functional_9\", \"trainable\": true, \"layers\": [{\"module\": \"keras.layers\", \"class_name\": \"InputLayer\", \"config\": {\"batch_shape\": [null, 256], \"dtype\": \"int32\", \"sparse\": false, \"name\": \"input_layer_2\"}, \"registered_name\": null, \"name\": \"input_layer_2\", \"inbound_nodes\": []}, {\"module\": \"keras.layers\", \"class_name\": \"Embedding\", \"config\": {\"name\": \"embedding_2\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"input_dim\": 99, \"output_dim\": 300, \"embeddings_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"RandomUniform\", \"config\": {\"seed\": null, \"minval\": -0.05, \"maxval\": 0.05}, \"registered_name\": null}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": false}, \"registered_name\": null, \"build_config\": {\"shapes_dict\": {}}, \"name\": \"embedding_2\", \"inbound_nodes\": [{\"args\": [{\"class_name\": \"__keras_tensor__\", \"config\": {\"shape\": [null, 256], \"dtype\": \"int32\", \"keras_history\": [\"input_layer_2\", 0, 0]}}], \"kwargs\": {}}]}, {\"module\": \"keras.layers\", \"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional_3\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"merge_mode\": \"concat\", \"layer\": {\"module\": \"keras.layers\", \"class_name\": \"LSTM\", \"config\": {\"name\": \"forward_lstm_3\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"return_sequences\": true, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": true, \"units\": 128, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Orthogonal\", \"config\": {\"seed\": null, \"gain\": 1.0}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 256, 300]}}, \"backward_layer\": {\"module\": \"keras.layers\", \"class_name\": \"LSTM\", \"config\": {\"name\": \"backward_lstm_3\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"return_sequences\": true, \"return_state\": false, \"go_backwards\": true, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": true, \"units\": 128, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Orthogonal\", \"config\": {\"seed\": null, \"gain\": 1.0}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 256, 300]}}}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 256, 300]}, \"name\": \"bidirectional_3\", \"inbound_nodes\": [{\"args\": [{\"class_name\": \"__keras_tensor__\", \"config\": {\"shape\": [null, 256, 300], \"dtype\": \"float32\", \"keras_history\": [\"embedding_2\", 0, 0]}}], \"kwargs\": {\"mask\": null}}]}, {\"module\": null, \"class_name\": \"Attention\", \"config\": {\"name\": \"attention\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}}, \"registered_name\": \"Custom>Attention\", \"build_config\": {\"input_shape\": [null, 256, 256]}, \"name\": \"attention\", \"inbound_nodes\": [{\"args\": [{\"class_name\": \"__keras_tensor__\", \"config\": {\"shape\": [null, 256, 256], \"dtype\": \"float32\", \"keras_history\": [\"bidirectional_3\", 0, 0]}}], \"kwargs\": {\"mask\": null}}]}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"units\": 256, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 256]}, \"name\": \"dense_1\", \"inbound_nodes\": [{\"args\": [{\"class_name\": \"__keras_tensor__\", \"config\": {\"shape\": [null, 256], \"dtype\": \"float32\", \"keras_history\": [\"attention\", 0, 0]}}], \"kwargs\": {}}]}, {\"module\": \"keras.layers\", \"class_name\": \"BatchNormalization\", \"config\": {\"name\": \"batch_normalization_2\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"axis\": -1, \"momentum\": 0.99, \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"moving_mean_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"moving_variance_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null, \"synchronized\": false}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 256]}, \"name\": \"batch_normalization_2\", \"inbound_nodes\": [{\"args\": [{\"class_name\": \"__keras_tensor__\", \"config\": {\"shape\": [null, 256], \"dtype\": \"float32\", \"keras_history\": [\"dense_1\", 0, 0]}}], \"kwargs\": {\"mask\": null}}]}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"units\": 2199, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 256]}, \"name\": \"dense_2\", \"inbound_nodes\": [{\"args\": [{\"class_name\": \"__keras_tensor__\", \"config\": {\"shape\": [null, 256], \"dtype\": \"float32\", \"keras_history\": [\"batch_normalization_2\", 0, 0]}}], \"kwargs\": {}}]}], \"input_layers\": [[\"input_layer_2\", 0, 0]], \"output_layers\": [[\"dense_2\", 0, 0]]}, \"registered_name\": \"Functional\", \"build_config\": {\"input_shape\": null}, \"compile_config\": {\"optimizer\": {\"module\": \"keras.optimizers\", \"class_name\": \"Adam\", \"config\": {\"name\": \"adam\", \"learning_rate\": 0.0010000000474974513, \"weight_decay\": null, \"clipnorm\": null, \"global_clipnorm\": null, \"clipvalue\": null, \"use_ema\": false, \"ema_momentum\": 0.99, \"ema_overwrite_frequency\": null, \"loss_scale_factor\": null, \"gradient_accumulation_steps\": null, \"beta_1\": 0.9, \"beta_2\": 0.999, \"epsilon\": 1e-07, \"amsgrad\": false}, \"registered_name\": null}, \"loss\": \"categorical_crossentropy\", \"loss_weights\": null, \"metrics\": [\"accuracy\"], \"weighted_metrics\": null, \"run_eagerly\": false, \"steps_per_execution\": 1, \"jit_compile\": false}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complicated Solution"
      ],
      "metadata": {
        "id": "tzSH6gMhPyZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To Check the Weights Available in Model Weights File"
      ],
      "metadata": {
        "id": "CJJ-h0HSRNQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HEyUjk2NRND7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "def print_h5_structure(name, obj):\n",
        "    if isinstance(obj, h5py.Dataset):\n",
        "        print(f\"Dataset: {name}, Shape: {obj.shape}, Type: {obj.dtype}\")\n",
        "    elif isinstance(obj, h5py.Group):\n",
        "        print(f\"Group: {name}\")\n",
        "\n",
        "with h5py.File('char_attn_lstm_model.h5', 'r') as f:\n",
        "    f.visititems(print_h5_structure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHV14ILTIXOH",
        "outputId": "4b0c955a-1e72-47c0-84ff-05b6c65f8805"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group: attention_20\n",
            "Group: attention_20/attention_20\n",
            "Dataset: attention_20/attention_20/attention_20_W:0, Shape: (512,), Type: float32\n",
            "Dataset: attention_20/attention_20/attention_20_b:0, Shape: (256,), Type: float32\n",
            "Group: batch_normalization_59\n",
            "Group: batch_normalization_59/batch_normalization_59\n",
            "Dataset: batch_normalization_59/batch_normalization_59/beta:0, Shape: (1024,), Type: float32\n",
            "Dataset: batch_normalization_59/batch_normalization_59/gamma:0, Shape: (1024,), Type: float32\n",
            "Dataset: batch_normalization_59/batch_normalization_59/moving_mean:0, Shape: (1024,), Type: float32\n",
            "Dataset: batch_normalization_59/batch_normalization_59/moving_variance:0, Shape: (1024,), Type: float32\n",
            "Group: bidirectional_21\n",
            "Group: bidirectional_21/bidirectional_21\n",
            "Group: bidirectional_21/bidirectional_21/backward_lstm_21\n",
            "Dataset: bidirectional_21/bidirectional_21/backward_lstm_21/bias:0, Shape: (1024,), Type: float32\n",
            "Dataset: bidirectional_21/bidirectional_21/backward_lstm_21/kernel:0, Shape: (300, 1024), Type: float32\n",
            "Dataset: bidirectional_21/bidirectional_21/backward_lstm_21/recurrent_kernel:0, Shape: (256, 1024), Type: float32\n",
            "Group: bidirectional_21/bidirectional_21/forward_lstm_21\n",
            "Dataset: bidirectional_21/bidirectional_21/forward_lstm_21/bias:0, Shape: (1024,), Type: float32\n",
            "Dataset: bidirectional_21/bidirectional_21/forward_lstm_21/kernel:0, Shape: (300, 1024), Type: float32\n",
            "Dataset: bidirectional_21/bidirectional_21/forward_lstm_21/recurrent_kernel:0, Shape: (256, 1024), Type: float32\n",
            "Group: dense_118\n",
            "Group: dense_118/dense_118\n",
            "Dataset: dense_118/dense_118/bias:0, Shape: (1024,), Type: float32\n",
            "Dataset: dense_118/dense_118/kernel:0, Shape: (512, 1024), Type: float32\n",
            "Group: dense_119\n",
            "Group: dense_119/dense_119\n",
            "Dataset: dense_119/dense_119/bias:0, Shape: (2199,), Type: float32\n",
            "Dataset: dense_119/dense_119/kernel:0, Shape: (1024, 2199), Type: float32\n",
            "Group: dropout_66\n",
            "Group: dropout_67\n",
            "Group: embedding_60\n",
            "Group: embedding_60/embedding_60\n",
            "Dataset: embedding_60/embedding_60/embeddings:0, Shape: (99, 300), Type: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To Check the Weights Required in Model Json Files"
      ],
      "metadata": {
        "id": "WERAPDu4SApg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_model = model.to_json()\n",
        "tmp_model = keras.models.model_from_json(config_model, custom_objects={'Attention': Attention()})\n",
        "\n",
        "for layer in tmp_model.layers:\n",
        "    print(layer.name)\n",
        "    print([w.shape for w in tmp_model.get_layer(layer.name).get_weights()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUHB7UH5IXLb",
        "outputId": "042be4f4-ad41-48a6-d38c-9f4a43c7f12a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer_27\n",
            "[]\n",
            "embedding_60\n",
            "[(99, 300)]\n",
            "bidirectional_21\n",
            "[(300, 1024), (256, 1024), (1024,), (300, 1024), (256, 1024), (1024,)]\n",
            "attention_20\n",
            "[(512,), (256,)]\n",
            "dense_118\n",
            "[(512, 1024), (1024,)]\n",
            "batch_normalization_59\n",
            "[(1024,), (1024,), (1024,), (1024,)]\n",
            "dense_119\n",
            "[(1024, 2199), (2199,)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assign Weights to Model"
      ],
      "metadata": {
        "id": "h5eQytViUoMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# json_file = open(\"char_attn_lstm_model_upd2025.json\",\"r\")\n",
        "json_file = open(\"test2.json\",\"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "tmp_model = model_from_json(loaded_model_json, custom_objects={'Attention': Attention()})"
      ],
      "metadata": {
        "id": "-kaW74cbVBAb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "with h5py.File('char_attn_lstm_model.h5', 'r') as f:\n",
        "    tmp_dict = {\n",
        "        'attention_20_W': f['attention_20']['attention_20']['attention_20_W:0'][()],\n",
        "        'attention_20_b': f['attention_20']['attention_20']['attention_20_b:0'][()],\n",
        "        'batch_normalization_59_beta': f['batch_normalization_59']['batch_normalization_59']['beta:0'][()],\n",
        "        'batch_normalization_59_gamma': f['batch_normalization_59']['batch_normalization_59']['gamma:0'][()],\n",
        "        'batch_normalization_59_moving_mean': f['batch_normalization_59']['batch_normalization_59']['moving_mean:0'][()],\n",
        "        'batch_normalization_59_moving_variance': f['batch_normalization_59']['batch_normalization_59']['moving_variance:0'][()],\n",
        "        'backward_lstm_21_bias': f['bidirectional_21']['bidirectional_21']['backward_lstm_21']['bias:0'][()],\n",
        "        'backward_lstm_21_kernel': f['bidirectional_21']['bidirectional_21']['backward_lstm_21']['kernel:0'][()],\n",
        "        'backward_lstm_21_recurrent_kernel': f['bidirectional_21']['bidirectional_21']['backward_lstm_21']['recurrent_kernel:0'][()],\n",
        "        'forward_lstm_21_bias': f['bidirectional_21']['bidirectional_21']['forward_lstm_21']['bias:0'][()],\n",
        "        'forward_lstm_21_kernel': f['bidirectional_21']['bidirectional_21']['forward_lstm_21']['kernel:0'][()],\n",
        "        'forward_lstm_21_recurrent_kernel': f['bidirectional_21']['bidirectional_21']['forward_lstm_21']['recurrent_kernel:0'][()],\n",
        "        'dense_118_bias': f['dense_118']['dense_118']['bias:0'][()],\n",
        "        'dense_118_kernel': f['dense_118']['dense_118']['kernel:0'][()],\n",
        "        'dense_119_bias': f['dense_119']['dense_119']['bias:0'][()],\n",
        "        'dense_119_kernel': f['dense_119']['dense_119']['kernel:0'][()],\n",
        "        'embedding_60': f['embedding_60']['embedding_60']['embeddings:0'][()],\n",
        "        }"
      ],
      "metadata": {
        "id": "koKv81SdUuvj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set dense_119\n",
        "tmp_model.get_layer('dense_119').set_weights([tmp_dict['dense_119_kernel'], tmp_dict['dense_119_bias']])\n",
        "# Set dense_118\n",
        "tmp_model.get_layer('dense_118').set_weights([tmp_dict['dense_118_kernel'], tmp_dict['dense_118_bias']])\n",
        "# Embedding:\n",
        "tmp_model.get_layer('embedding_60').set_weights([tmp_dict['embedding_60']])\n",
        "# bidirectional_21\n",
        "tmp_model.get_layer('bidirectional_21').set_weights([\n",
        "    tmp_dict['forward_lstm_21_kernel'], tmp_dict['forward_lstm_21_recurrent_kernel'],\n",
        "    tmp_dict['forward_lstm_21_bias'], tmp_dict['backward_lstm_21_kernel'],\n",
        "    tmp_dict['backward_lstm_21_recurrent_kernel'],\n",
        "    tmp_dict['backward_lstm_21_bias']])\n",
        "# attention_20\n",
        "tmp_model.get_layer('attention_20').set_weights([tmp_dict['attention_20_W'], tmp_dict['attention_20_b']])\n",
        "\n",
        "# batch_normalization_59\n",
        "tmp_model.get_layer('batch_normalization_59').set_weights([\n",
        "    tmp_dict['batch_normalization_59_beta'], tmp_dict['batch_normalization_59_gamma'],\n",
        "    tmp_dict['batch_normalization_59_moving_mean'], tmp_dict['batch_normalization_59_moving_variance']])"
      ],
      "metadata": {
        "id": "n8-GpuaQIXI3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sELdwhR-IXGI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}